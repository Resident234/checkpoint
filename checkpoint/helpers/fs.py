"""
File system utilities and duplicate handling
"""
import os
import re
import shutil
import hashlib
from pathlib import Path
from typing import Set, List, Tuple, Optional
from checkpoint import globals as gb


def ensure_temp_directory() -> Path:
    """
    –°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    
    Returns:
        Path: –ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞ (–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è pyproject.toml)
    current_file = Path(__file__)
    project_root = current_file.parent.parent.parent  # checkpoint/helpers/temp_dir.py -> CheckPoint/
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    temp_dir = project_root / "temp"
    
    if not temp_dir.exists():
        temp_dir.mkdir(parents=True, exist_ok=True)
        gb.rc.print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {temp_dir}", style="blue")
    
    return temp_dir


def get_temp_path(filename: str) -> Path:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
    
    Args:
        filename: –ò–º—è —Ñ–∞–π–ª–∞
        
    Returns:
        Path: –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    """
    temp_dir = ensure_temp_directory()
    return temp_dir / filename


# =============================================================================
# DUPLICATE FILE HANDLING METHODS
# =============================================================================

def calculate_file_hash(file_path: Path, algorithm: str = 'md5') -> str:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Ñ–∞–π–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        algorithm: –ê–ª–≥–æ—Ä–∏—Ç–º —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è ('md5', 'sha1', 'sha256')
        
    Returns:
        str: –•–µ—à —Ñ–∞–π–ª–∞ –≤ –≤–∏–¥–µ —Å—Ç—Ä–æ–∫–∏
        
    Raises:
        FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
        ValueError: –ï—Å–ª–∏ –∞–ª–≥–æ—Ä–∏—Ç–º –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è
    """
    if not file_path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
    
    # –†–∞–∑–º–µ—Ä –±—É—Ñ–µ—Ä–∞ –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ (64KB)
    BUF_SIZE = 65536
    
    # –í—ã–±–∏—Ä–∞–µ–º –∞–ª–≥–æ—Ä–∏—Ç–º —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
    hash_algorithms = {
        'md5': hashlib.md5,
        'sha1': hashlib.sha1,
        'sha256': hashlib.sha256
    }
    
    if algorithm not in hash_algorithms:
        raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º: {algorithm}. –î–æ—Å—Ç—É–ø–Ω—ã: {list(hash_algorithms.keys())}")
    
    hash_obj = hash_algorithms[algorithm]()
    
    try:
        with open(file_path, 'rb') as f:
            while True:
                data = f.read(BUF_SIZE)
                if not data:
                    break
                hash_obj.update(data)
        
        return hash_obj.hexdigest()
    
    except Exception as e:
        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —Ö–µ—à–∞ —Ñ–∞–π–ª–∞ {file_path}: {e}", style="red")
        raise


def is_duplicate_by_filename(filename: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –¥—É–±–ª–µ–º –ø–æ –∏–º–µ–Ω–∏ (–∏–º–µ–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å _2, _3 –∏ —Ç.–¥.)
    
    Args:
        filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
    Returns:
        bool: True –µ—Å–ª–∏ —Ñ–∞–π–ª —è–≤–ª—è–µ—Ç—Å—è –¥—É–±–ª–µ–º
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å—É—Ñ—Ñ–∏–∫—Å–∞ –¥—É–±–ª—è: _—á–∏—Å–ª–æ –ø–µ—Ä–µ–¥ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º
    pattern = r'_\d+\.[^.]+$'
    return bool(re.search(pattern, filename))


def find_duplicates_by_hash(
    directory: Path, 
    extensions: Optional[List[str]] = None,
    algorithm: str = 'md5',
    recursive: bool = True
) -> Tuple[List[Tuple[str, List[Path]]], int]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ —Ö–µ—à—É
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        extensions: –°–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ['.jpg', '.png'])
        algorithm: –ê–ª–≥–æ—Ä–∏—Ç–º —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        recursive: –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
        
    Returns:
        Tuple[List[Tuple[str, List[Path]]], int]: 
            (—Å–ø–∏—Å–æ–∫ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (—Ö–µ—à, —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π), –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    """
    if not directory.exists():
        gb.rc.print(f"‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}", style="yellow")
        return [], 0
    
    file_hashes = {}
    total_duplicates = 0
    
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –æ–±—Ö–æ–¥–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if recursive:
            file_paths = directory.rglob('*')
        else:
            file_paths = directory.glob('*')
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã
        for file_path in file_paths:
            if not file_path.is_file():
                continue
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –∑–∞–¥–∞–Ω —Ñ–∏–ª—å—Ç—Ä
            if extensions and file_path.suffix.lower() not in [ext.lower() for ext in extensions]:
                continue
            
            try:
                file_hash = calculate_file_hash(file_path, algorithm)
                
                if file_hash in file_hashes:
                    file_hashes[file_hash].append(file_path)
                else:
                    file_hashes[file_hash] = [file_path]
                    
            except Exception as e:
                gb.rc.print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file_path}: {e}", style="yellow")
                continue
        
        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –≥—Ä—É–ø–ø—ã —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏ (–±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)
        duplicate_groups = [(hash_val, paths) for hash_val, paths in file_hashes.items() if len(paths) > 1]
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∏—Å–∫–ª—é—á–∞—è –æ—Ä–∏–≥–∏–Ω–∞–ª—ã)
        for _, paths in duplicate_groups:
            total_duplicates += len(paths) - 1  # -1 –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–¥–∏–Ω —Ñ–∞–π–ª - –æ—Ä–∏–≥–∏–Ω–∞–ª
        
        gb.rc.print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(duplicate_groups)} –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, –≤—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_duplicates}", style="blue")
        
        return duplicate_groups, total_duplicates
        
    except Exception as e:
        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ {directory}: {e}", style="red")
        return [], 0


def find_duplicates_by_filename(
    directory: Path,
    recursive: bool = True
) -> Tuple[List[Path], int]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ –∏–º–µ–Ω–∏ (—Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ _2, _3 –∏ —Ç.–¥.)
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        recursive: –†–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
        
    Returns:
        Tuple[List[Path], int]: (—Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –¥—É–±–ª–∏–∫–∞—Ç–∞–º, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    """
    if not directory.exists():
        gb.rc.print(f"‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}", style="yellow")
        return [], 0
    
    duplicate_files = []
    
    try:
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–æ–¥ –æ–±—Ö–æ–¥–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        if recursive:
            file_paths = directory.rglob('*')
        else:
            file_paths = directory.glob('*')
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
        for file_path in file_paths:
            if file_path.is_file() and is_duplicate_by_filename(file_path.name):
                duplicate_files.append(file_path)
        
        gb.rc.print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(duplicate_files)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞", style="blue")
        
        return duplicate_files, len(duplicate_files)
        
    except Exception as e:
        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏ –≤ {directory}: {e}", style="red")
        return [], 0


def get_unique_filename(target_path: Path) -> Path:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞, –¥–æ–±–∞–≤–ª—è—è —á–∏—Å–ª–æ –∫ –∏–º–µ–Ω–∏ –ø—Ä–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–µ
    –ï—Å–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –¥—É–±–ª–µ–º (–∏–º–µ–µ—Ç –Ω–æ–º–µ—Ä –≤ –∫–æ–Ω—Ü–µ),
    —Å—á–µ—Ç—á–∏–∫ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —ç—Ç–æ–≥–æ –Ω–æ–º–µ—Ä–∞ + 1
    
    Args:
        target_path: –ü—É—Ç—å –∫ —Ü–µ–ª–µ–≤–æ–º—É —Ñ–∞–π–ª—É
        
    Returns:
        Path: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
    """
    if not target_path.exists():
        return target_path
    
    stem = target_path.stem
    suffix = target_path.suffix
    parent = target_path.parent
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ –¥—É–±–ª–µ–º (–∏–º–µ–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å _—á–∏—Å–ª–æ)
    duplicate_pattern = r'_(\d+)$'
    match = re.search(duplicate_pattern, stem)
    
    if match:
        # –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ –¥—É–±–ª—å, –∏–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤–æ–µ –∏–º—è –∏ –Ω–æ–º–µ—Ä
        existing_number = int(match.group(1))
        base_stem = stem[:match.start()]  # –ò–º—è –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ _—á–∏—Å–ª–æ
        counter = existing_number + 1
    else:
        # –ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–µ –¥—É–±–ª—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω–æ–µ –∏–º—è –∫–∞–∫ –±–∞–∑—É
        base_stem = stem
        counter = 1
    
    while True:
        new_name = f"{base_stem}_{counter}{suffix}"
        new_path = parent / new_name
        if not new_path.exists():
            return new_path
        counter += 1


def merge_directories(src_dir: Path, dst_dir: Path, conflict_resolution: str = 'rename') -> bool:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–≤—É—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, —Ä–∞–∑—Ä–µ—à–∞—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∏–º–µ–Ω
    
    Args:
        src_dir: –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        dst_dir: –¶–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        conflict_resolution: –°–ø–æ—Å–æ–± —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤:
            - 'rename': –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ —Ñ–∞–π–ª—ã
            - 'skip': –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—â–∏–µ —Ñ–∞–π–ª—ã
            - 'overwrite': –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
            
    Returns:
        bool: True –µ—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ
    """
    if not src_dir.exists():
        gb.rc.print(f"‚ö†Ô∏è –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {src_dir}", style="yellow")
        return False
    
    if not src_dir.is_dir():
        gb.rc.print(f"‚ö†Ô∏è –ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π: {src_dir}", style="yellow")
        return False
    
    # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    dst_dir.mkdir(parents=True, exist_ok=True)
    
    try:
        for item in src_dir.iterdir():
            target_item = dst_dir / item.name
            
            if item.is_file():
                if target_item.exists():
                    if conflict_resolution == 'rename':
                        # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è
                        unique_target = get_unique_filename(target_item)
                        shutil.move(str(item), str(unique_target))
                        gb.rc.print(f"üìÑ –§–∞–π–ª –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω: {item.name} ‚Üí {unique_target.name}", style="yellow")
                    elif conflict_resolution == 'skip':
                        gb.rc.print(f"‚è≠Ô∏è –§–∞–π–ª –ø—Ä–æ–ø—É—â–µ–Ω (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç): {item.name}", style="cyan")
                        continue
                    elif conflict_resolution == 'overwrite':
                        shutil.move(str(item), str(target_item))
                        gb.rc.print(f"üîÑ –§–∞–π–ª –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω: {item.name}", style="orange")
                else:
                    shutil.move(str(item), str(target_item))
                    
            elif item.is_dir():
                if target_item.exists():
                    # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ
                    gb.rc.print(f"üìÅ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–∞–ø–æ–∫: {item.name}", style="cyan")
                    merge_directories(item, target_item, conflict_resolution)
                    # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø–æ—Å–ª–µ —Å–ª–∏—è–Ω–∏—è
                    if item.exists():
                        shutil.rmtree(str(item))
                else:
                    shutil.move(str(item), str(target_item))
        
        return True
        
    except Exception as e:
        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {e}", style="red")
        return False


def remove_duplicates(
    directory: Path,
    method: str = 'hash',
    extensions: Optional[List[str]] = None,
    dry_run: bool = True,
    keep_newest: bool = True
) -> Tuple[int, List[Path]]:
    """
    –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        method: –ú–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ('hash' –∏–ª–∏ 'filename')
        extensions: –°–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
        keep_newest: –ï—Å–ª–∏ True, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–∞–º—ã–π –Ω–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑ –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        
    Returns:
        Tuple[int, List[Path]]: (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, —Å–ø–∏—Å–æ–∫ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –ø—É—Ç–µ–π)
    """
    if not directory.exists():
        gb.rc.print(f"‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}", style="yellow")
        return 0, []
    
    removed_count = 0
    removed_files = []
    
    try:
        if method == 'hash':
            duplicate_groups, _ = find_duplicates_by_hash(directory, extensions)
            
            for hash_val, file_paths in duplicate_groups:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
                sorted_files = sorted(file_paths, key=lambda x: x.stat().st_mtime, reverse=keep_newest)
                
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∫—Ä–æ–º–µ –ø–µ—Ä–≤–æ–≥–æ (—Å–∞–º–æ–≥–æ –Ω–æ–≤–æ–≥–æ –∏–ª–∏ —Å—Ç–∞—Ä–æ–≥–æ)
                files_to_remove = sorted_files[1:]
                
                for file_path in files_to_remove:
                    if dry_run:
                        gb.rc.print(f"üóëÔ∏è [DRY RUN] –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω: {file_path}", style="yellow")
                    else:
                        try:
                            file_path.unlink()
                            gb.rc.print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {file_path}", style="green")
                            removed_count += 1
                            removed_files.append(file_path)
                        except Exception as e:
                            gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path}: {e}", style="red")
        
        elif method == 'filename':
            duplicate_files, _ = find_duplicates_by_filename(directory)
            
            for file_path in duplicate_files:
                if dry_run:
                    gb.rc.print(f"üóëÔ∏è [DRY RUN] –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω: {file_path}", style="yellow")
                else:
                    try:
                        file_path.unlink()
                        gb.rc.print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {file_path}", style="green")
                        removed_count += 1
                        removed_files.append(file_path)
                    except Exception as e:
                        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file_path}: {e}", style="red")
        
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π –º–µ—Ç–æ–¥: {method}. –î–æ—Å—Ç—É–ø–Ω—ã: 'hash', 'filename'")
        
        if dry_run:
            gb.rc.print(f"üìä [DRY RUN] –ù–∞–π–¥–µ–Ω–æ {len(removed_files)} —Ñ–∞–π–ª–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è", style="blue")
        else:
            gb.rc.print(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤", style="green")
        
        return removed_count, removed_files
        
    except Exception as e:
        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}", style="red")
        return 0, []


def get_duplicate_statistics(
    directory: Path,
    extensions: Optional[List[str]] = None,
    include_hash_duplicates: bool = True,
    include_filename_duplicates: bool = True
) -> dict:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    
    Args:
        directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        extensions: –°–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        include_hash_duplicates: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –ø–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —Ö–µ—à—É
        include_filename_duplicates: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –ø–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –∏–º–µ–Ω–∏
        
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    """
    stats = {
        'directory': str(directory),
        'hash_duplicates': {'groups': 0, 'files': 0, 'details': []},
        'filename_duplicates': {'files': 0, 'details': []},
        'total_duplicates': 0
    }
    
    if not directory.exists():
        gb.rc.print(f"‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {directory}", style="yellow")
        return stats
    
    try:
        if include_hash_duplicates:
            duplicate_groups, hash_duplicates_count = find_duplicates_by_hash(directory, extensions)
            stats['hash_duplicates']['groups'] = len(duplicate_groups)
            stats['hash_duplicates']['files'] = hash_duplicates_count
            stats['hash_duplicates']['details'] = [(hash_val, [str(p) for p in paths]) for hash_val, paths in duplicate_groups]
        
        if include_filename_duplicates:
            filename_duplicates, filename_duplicates_count = find_duplicates_by_filename(directory)
            stats['filename_duplicates']['files'] = filename_duplicates_count
            stats['filename_duplicates']['details'] = [str(p) for p in filename_duplicates]
        
        stats['total_duplicates'] = stats['hash_duplicates']['files'] + stats['filename_duplicates']['files']
        
        gb.rc.print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –¥–ª—è {directory}:", style="blue")
        gb.rc.print(f"   üîó –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ —Ö–µ—à—É: {stats['hash_duplicates']['files']} —Ñ–∞–π–ª–æ–≤ –≤ {stats['hash_duplicates']['groups']} –≥—Ä—É–ø–ø–∞—Ö", style="cyan")
        gb.rc.print(f"   üìù –î—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∏–º–µ–Ω–∏: {stats['filename_duplicates']['files']} —Ñ–∞–π–ª–æ–≤", style="cyan")
        gb.rc.print(f"   üìÅ –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['total_duplicates']}", style="green")
        
        return stats
        
    except Exception as e:
        gb.rc.print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}", style="red")
        return stats


def clean_folder_name(folder_name: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –∏–º—è –ø–∞–ø–∫–∏ –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å—É—Ñ—Ñ–∏–∫—Å–∞
    
    Args:
        folder_name: –ò—Å—Ö–æ–¥–Ω–æ–µ –∏–º—è –ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2016Novorossijsk_1GrOsmhKAQ")
        
    Returns:
        str: –û—á–∏—â–µ–Ω–Ω–æ–µ –∏–º—è –ø–∞–ø–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "2016Novorossijsk")
    """
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å—É—Ñ—Ñ–∏–∫—Å–∞: –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ + —Å–ª—É—á–∞–π–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –∫–æ–Ω—Ü–µ
    pattern = r'_[A-Za-z0-9]+$'
    cleaned_name = re.sub(pattern, '', folder_name)
    return cleaned_name
